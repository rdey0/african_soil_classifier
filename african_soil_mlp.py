# -*- coding: utf-8 -*-
"""african_soil_mlp.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1onG0yxdpU7_9JmkPpN1p-jTN7biyxGPw
"""



# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import StandardScaler
### SCRIPT ###
# import African soil data
my_path = './african_soil.csv'
soil = pd.read_csv(my_path)
X = soil.iloc[:,list(range(1,3594)) + [3497]]
Y = pd.DataFrame(soil.loc[:,'Depth'])
ph = pd.DataFrame(soil.loc[:,'pH'])
# separate test and training data
x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=250)
# scale data
scaler = StandardScaler()
scaler.fit(x_train)
x_train = scaler.transform(x_train)
x_test = scaler.transform(x_test)
# parameters to be tested exhaustively with grid search
parameter_space = {
    'hidden_layer_sizes': [(10,10,10), (20,20,20), (30,30,30), (40,40,40)],
    'activation': ['identity', 'logistic', 'tanh', 'relu'],
    'solver': ['lbfgs','sgd', 'adam'],
    'learning_rate': ['constant','adaptive'],
    'max_iter': [100, 200, 300]
}
# train MLP model with grid search
mlp = MLPClassifier()
clf = GridSearchCV(mlp, parameter_space, n_jobs=-1, cv=7)
clf.fit(x_train, np.ravel(y_train))
# make predictions
y_pred = clf.predict(x_test)
# print training results
print("Grid scores on development set:")
means = clf.cv_results_['mean_test_score']
stds = clf.cv_results_['std_test_score']
for mean, std, params in zip(means, stds, clf.cv_results_['params']):
    print("%0.3f (+/-%0.03f) for %r"
#         % (mean, std * 2, params))
print()
print("Best parameters set found on development set:")
print(clf.best_params_)
print()
print('Accuracy:')
print(accuracy_score(y_test, y_pred))